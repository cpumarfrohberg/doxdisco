from typing import Callable, List

from minsearch import Index
from sentence_transformers import SentenceTransformer

from config import (
    SearchType,
    SentenceTransformerModel,
    openai_client,
)
from fetch_prep_data.parser import parse_data
from fetch_prep_data.reader import read_github_data
from prompt.chunking_utils import chunk_documents
from prompt.llm_utils import query_with_context
from prompt.vector_search import create_vector_index


class TextRAG:
    """RAG implementation for GitHub repository analysis with multiple search types"""

    def __init__(
        self,
        search_type: str = SearchType.TEXT,
        model_name: str = SentenceTransformerModel.ALL_MINILM_L6_V2,
        text_fields: List[str] | None = None,
    ):
        self.search_type = search_type
        self.model_name = model_name
        self.text_fields = (
            text_fields
            if text_fields is not None
            else [
                "content",
                "filename",
                "title",
                "description",
            ]
        )
        self.documents = []
        self.chunks = []
        self.index = None
        self.embedder = None

        if search_type == SearchType.VECTOR_SENTENCE_TRANSFORMERS:
            self.embedder = SentenceTransformer(model_name)

    def load_repository(
        self,
        repo_owner: str,
        repo_name: str,
        allowed_extensions: set | None = None,
        filename_filter: Callable | None = None,
        chunk_size: int | None = None,
        chunk_step: int | None = None,
    ):
        """Load and process GitHub repository data"""

        github_data = read_github_data(
            repo_owner=repo_owner,
            repo_name=repo_name,
            allowed_extensions=allowed_extensions,
            filename_filter=filename_filter,
        )

        parsed_data = parse_data(github_data)

        self.chunks = chunk_documents(parsed_data, size=chunk_size, step=chunk_step)
        print(f"ðŸ“ Created {len(self.chunks)} document chunks")

        if self.search_type == SearchType.TEXT:
            # Standard text search with minsearch
            self.index = Index(text_fields=self.text_fields)
            self.index.fit(self.chunks)
        elif self.search_type == SearchType.VECTOR_MINSEARCH:
            # Minsearch with embeddings (placeholder for future implementation)
            self.index = Index(text_fields=self.text_fields)
            self.index.fit(self.chunks)
            print("âš ï¸  Vector minsearch not yet implemented, using text search")
        elif self.search_type == SearchType.VECTOR_SENTENCE_TRANSFORMERS:
            # SentenceTransformers vector search
            if self.embedder is None:
                raise ValueError("SentenceTransformer model not initialized")
            self.index = create_vector_index(self.chunks, self.embedder)
        else:
            raise ValueError(f"Unsupported search type: {self.search_type}")

        self.documents = parsed_data

    def query(self, question: str, instruction_type: str = "faq_assistant") -> str:
        """Query the repository using text-based search"""
        if not self.index:
            raise ValueError("No repository loaded. Call load_repository() first.")

        return query_with_context(
            question=question,
            index=self.index,
            instruction_type=instruction_type,
            openai_client=openai_client,
        )
